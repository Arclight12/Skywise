
# ðŸŒ Intelligent Downlink Prioritization for Earth Observation Satellites

### *A Comparative Study of Classical AI Algorithms for Data Classification and Scheduling*

---

## ðŸ“˜ Overview

Earth Observation (EO) satellites capture **massive volumes of imagery and sensor data** every day â€” far more than what can be transmitted to Earth in real time due to **limited bandwidth and visibility windows**.
This creates a need for an **intelligent prioritization and scheduling system** that can decide:

* Which data is **important enough** to transmit first
* How to **schedule** those transmissions efficiently

Our project implements an **AI-inspired decision system** that performs both **classification** and **scheduling**, using classical algorithms instead of machine learning models.

---

## ðŸ§  The Original Idea (and Why We â€œPCAâ€™dâ€ It)

Initially, the project was conceptualized as a **machine learningâ€“based system**:

* The plan was to train an **AI model** capable of learning from past satellite data to classify and prioritize new data intelligently.
* This would have involved deep learning models that interpret spatial, temporal, and contextual importance.

However, after feedback from our faculty guide, we were advised to **simplify the scope** to a level that uses **concepts weâ€™ve learned in class**, while still maintaining the intelligence of the original idea.

So, just like applying **PCA (Principal Component Analysis)** to reduce a complex dataset into its most important features,
we **dimensionally reduced** our original concept from a full ML system into **algorithmic components** that simulate intelligent behavior using classical AI techniques â€”
namely, **Tree-based Filtering** and **Heuristic Search Algorithms**.

This approach preserves the logical essence of the ML design (decision-making + optimization) while keeping it implementation-friendly and educational.

---

## âš™ï¸ System Architecture

Our system works in **two stages**, reflecting how an AI model might first classify and then optimize actions.

### **1ï¸âƒ£ Stage 1: Tree-Based Filtering (Classification)**

This common module simulates the â€œlearningâ€ and â€œdecisionâ€ stage of an AI system.

* Each incoming satellite data point (e.g., an image) is evaluated based on:

  * **Region importance** (e.g., disaster-prone or coastal areas)
  * **Event type** (e.g., flood, fire, storm)
  * **Cloud cover**
  * **Image quality**
  * **Recency** (how old the data is)

* Using these features, a **decision tree** evaluates each data nodeâ€™s usefulness.
  Low-value or redundant data is **pruned using alphaâ€“beta pruning**, leaving only high-importance data for scheduling.

This stage answers:
ðŸ“¸ *â€œWhich data is worth sending?â€*

---

### **2ï¸âƒ£ Stage 2: Scheduling (Optimization)**

After filtering, we have a set of valuable data points.
The next challenge is to decide **in what order to transmit them**, considering:

* Bandwidth limits
* Energy consumption
* Ground station visibility windows

This is where we use **three different algorithms** â€” each implemented by one team member.

| Algorithm               | Approach           | Description                                                                                                                    |
| ----------------------- | ------------------ | ------------------------------------------------------------------------------------------------------------------------------ |
| **Greedy (Heuristic)**  | Deterministic      | Picks the highest-score data first and assigns the earliest available slot (fast and straightforward).                         |
| **A* Search**           | Graph-based search | Explores possible schedules as paths in a state space, guided by a heuristic that estimates total mission value.               |
| **Simulated Annealing** | Probabilistic      | Starts with a random schedule and iteratively improves it by controlled randomization, mimicking thermal annealing in physics. |

This stage answers:
ðŸ•’ *â€œWhen and in what order should data be sent?â€*

---

## ðŸ§© Project Structure

```
satellite_prioritization_project/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ satellite_data.csv          # Common input dataset
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ datamodel.py                # Defines DataNode class (data structure)
â”‚   â”œâ”€â”€ filter.py                   # Common tree-based filtering logic
â”‚   â””â”€â”€ reference_priority.py       # Reference importance weights
â”‚
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ algo1_greedy.py             # Greedy / heuristic scheduling (Kalidas)
â”‚   â”œâ”€â”€ algo2_astar.py              # A* search-based scheduling
â”‚   â””â”€â”€ algo3_simanneal.py          # Simulated annealing scheduling
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ greedy_schedule.csv
â”‚   â”œâ”€â”€ astar_schedule.csv
â”‚   â””â”€â”€ simanneal_schedule.csv
â”‚
â”œâ”€â”€ main.py                         # Runs filtering + all 3 algorithms
â””â”€â”€ comparison_plot.py              # Plots and compares results visually
```

---

## ðŸš€ How It Works (Step-by-Step)

1. **Load Data**

   * A dataset of satellite observations (`data/satellite_data.csv`) is loaded.
   * Each entry contains metadata like region, event type, quality, etc.

2. **Filter Data (Common Step)**

   * The `filter.py` module assigns each data point a **score** (0â€“100).
   * Low-value entries are pruned.

3. **Schedule (Algorithm-Specific)**

   * Each memberâ€™s algorithm independently schedules the filtered data.
   * Output is saved as CSV in the `outputs/` folder.

4. **Compare & Analyze**

   * `comparison_plot.py` plots and compares all three scheduling strategies.
   * Helps visualize differences in prioritization and performance.

---

## ðŸ“ˆ Example Comparison Graph

```
â†‘ Priority Score
â”‚
â”‚      â— Greedy
â”‚    â–² A*
â”‚  â–  Simulated Annealing
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Transmission Order
```

The chart reveals how each algorithm prioritizes data differently.
For example, A* may achieve a more balanced schedule, while greedy might favor high-score data immediately.

---

## ðŸ‘¨â€ðŸ’» Team Roles

| Member       | Role      | Contribution                                               |
| ------------ | --------- | ---------------------------------------------------------- |
| **Kalidas**  | Team Lead | Base setup, greedy scheduling, integration & visualization |
| **Aadarsh** | Developer | Implemented A* scheduling algorithm                        |
| **Vishnu S** | Developer | Implemented Simulated Annealing scheduling algorithm       |

All members contributed to code integration, testing, and analysis.

---

## ðŸŽ¯ Objectives Achieved

* âœ… Translated a **complex AI concept** into a classical algorithmic simulation
* âœ… Demonstrated the difference between **deterministic, search-based, and probabilistic** methods
* âœ… Implemented modular, comparable algorithms using a shared data pipeline
* âœ… Produced quantitative and visual comparisons for analysis

---

## ðŸ§© Future Enhancements

* Integrate an actual **ML model** to learn weights or heuristic values automatically.
* Incorporate **real satellite metadata** (e.g., from NASA Earth Data or ISRO open datasets).
* Extend scheduling logic to consider **energy optimization** and **multi-satellite networks**.
* Deploy the system as a **simulation dashboard** for educational or research use.

---

## ðŸ§  Key Concepts Used

* **Heuristic Search** (A*, Greedy, Simulated Annealing)
* **Alphaâ€“Beta Pruning** (Tree-based filtering)
* **Scheduling Optimization**
* **AI-inspired Decision Logic**
* **Feature-driven Evaluation without ML**

---

## ðŸª In Short

> This project began as an **AI model idea** for intelligent satellite downlink management.
>
> Through guided simplification, we **converted** that concept into a **classical AI simulation** â€”
> applying heuristic algorithms, search optimization, and pruning techniques to emulate intelligent decision-making.
>
> The result is a clean, modular system that blends **AI logic, optimization, and teamwork** â€”
> demonstrating how algorithmic thinking can achieve near-intelligent behavior even without machine learning.

---

## ðŸ“¸ Sample Output Snapshot

| Node ID | Region  | Event  | Score | Size (MB) | Start | End   |
| ------- | ------- | ------ | ----- | --------- | ----- | ----- |
| img_1   | coastal | flood  | 92.3  | 30        | 10:00 | 10:10 |
| img_2   | river   | fire   | 88.7  | 25        | 10:15 | 10:22 |
| img_3   | urban   | normal | 60.4  | 40        | 10:30 | 10:40 |

---

## ðŸ§© License

This project is open for educational and research use.
All algorithms are original implementations by the team.

---
